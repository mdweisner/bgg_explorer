---
title: "BGG Explorer Github"
author: "Michael Weisner and Chana Messinger"
date: "November 2, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Goals
+ K means cluster to recommendation?
+ Lasso penalized prediction of score
+ PCA Vector recommendation?

## To Do:
+ Talk to Ben about project (OK!)
+ Figure out what to do with data cleaning (DONE)
+ K Means: Do a plot and a tree visualization
+ + Also ask Ben about the clustering?
+ Run: lasso / ridge, randomforest, BART (Almost DONE)
+ + Pick best one
+ + Show actual examples of the best one
+ + Demonstrate made up examples (ex game with mechanics x and categories y and weight blah blah)
+ Document sections and give some analysis

## Libraries
```{r}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(psych)
```
## BGG Data
```{r}
games <- read_csv(unzip("~/bgg_explorer/bgg_db_1806.csv.zip"))
games2 <- games # just backup in case we need to go back to original values
```

## Quick Cleaning
I used this to quickly cut out some outliers, but they need closer examination!
A few things were decided here. 
+ One Night Ultimate Werewolf has the highest specified player count of 75. Some games list 99, seemingly to suggest unlimited players but this is not true and completely impractical. While they could be recoded, as there's no actual specified number of people it makes the data skewed and is easier to drop. 
+ Similarly, games with 0 players are useless as a game needs people.
+ There are two boardgames that are 21+ because they involve alcohol. One game has a suggested age of 42 which makes it somewhat useless for the context.
+ We will focus on "modern" games, choosing 1970 semi-arbitrarily. The 1980s and 1990s are considered the modern renaissance, so it seemed pertinent to look at games leading up to it. This is mostly to weed out ancient games, like go and chess that go back thousands of years and skew the sample.
+ Lastly, games with no category and mechanic are fundamentally useless, so they will be ignored here.
```{r}
games <- drop_na(games) # there's one NA column, annoyingly
outliers <- subset(games, min_players > 75 | max_players > 75 | max_players > 75 | min_players == 0 | max_players == 0 | weight == 0 | avg_time > 1000 | min_time > 1000 | max_time > 1000 | avg_time == 0 | min_time == 0 | max_time == 0 | age > 21 | year < 1970 | mechanic == "none" | category == "none")
games_clean <- subset(games, !(game_id %in% outliers$game_id))
#head(games_clean)
summary(games_clean)
```

Look at Outliers if necessary
```{r}
#View(outliers)
```

## Cleaning

### Drop Non-games
```{r echo=FALSE}
bad_ids <- c("18291", "21804", "23953", "125048", "5985", "10904") # either nonspecific games like 'traditional card games' or non-games in the system
```


### Incorrect Values
```{r}
# Years
# 108018 (riichi mahjong) is credited as being adapted in 1924
```


### Mechanics
https://boardgamegeek.com/browse/boardgamemechanic
Create Dummy Variables for each mechanic
```{r echo=FALSE}
mech_raw2 <- unlist(strsplit(games_clean$mechanic, ", "))
mech_unique <- unique(mech_raw2)
mech_terms <- sort(mech_unique)

# Add columns for each mechanic type
games_clean[, mech_terms] <- 0

# Update values of dummy mechanics if present in games_clean$mechanic
for(j in 1:length(mech_terms)){
  for(i in 1:length(games_clean$mechanic)){
    games_clean[i, as.character(mech_terms[j])] <- as.numeric(grepl(mech_terms[j], games_clean$mechanic[i]))
  }
  cat("now at", round(j * 1.96), "% ... ")
}


```

### Rename Mechanics

Test Rename
```{r}
### testing first
# colnames(games)
# testnames <- games[1:5, ]
# colnames(testnames) <- tolower(colnames(testnames))
# colnames(testnames) <- gsub("co-op", "coop", colnames(testnames)) # odd one out with dash
# colnames(testnames) <- gsub("\\/", " ", colnames(testnames))
# colnames(testnames) <- gsub("-", " ", colnames(testnames))
# colnames(testnames) <- gsub(" and ", " ", colnames(testnames))
# colnames(testnames) <- gsub("  ", " ", colnames(testnames))
# colnames(testnames) <- gsub("  ", " ", colnames(testnames))
# colnames(testnames) <- gsub(" ", "_", colnames(testnames))
```

```{r}
library(data.table)
colnames(games_clean) <- tolower(colnames(games_clean))
colnames(games_clean) <- gsub("co-op", "coop", colnames(games_clean)) # odd one out with dash
colnames(games_clean) <- gsub("\\/", " ", colnames(games_clean))
colnames(games_clean) <- gsub("&", "", colnames(games_clean))
colnames(games_clean) <- gsub("-", " ", colnames(games_clean))
colnames(games_clean) <- gsub(" and ", " ", colnames(games_clean))
colnames(games_clean) <- gsub("  ", " ", colnames(games_clean))
colnames(games_clean) <- gsub("  ", " ", colnames(games_clean))
colnames(games_clean) <- gsub(" ", "_", colnames(games_clean))
# colnames(games_clean) <- gsub("none", "no_mech", colnames(games_clean))

mech_old_names <- colnames(select(games_clean, acting:worker_placement))
mech_new_names <- paste0('mech_', mech_old_names)
setnames(games_clean, old = mech_old_names, new = mech_new_names)

head(select(games_clean, mech_acting:mech_worker_placement))
```

### Check Nones
```{r}
sum(games_clean$mech_none)
mech_miss <- games_clean[games_clean$mech_none == 1, ]
# games_clean <- rename(games_clean, no_mech = none )
```
### Total Mechanics
```{r}
games_clean <- games_clean %>%
  mutate(mech_total = rowSums(select(games_clean, mech_acting:mech_worker_placement)))
summary(games_clean$mech_total)
```

### Review Mech Stats
```{r}
describe(select(games_clean, mech_acting:mech_worker_placement))
```

### Categories
Do the same thing with categories
https://boardgamegeek.com/browse/boardgamecategory

```{r echo=FALSE}
cat_raw2 <- unlist(strsplit(games_clean$category, ", "))
cat_unique <- unique(cat_raw2)
cat_terms <- sort(cat_unique)

# Add columns for each mechanic type
games_clean[, cat_terms] <- 0

# Update values of dummy mechanics if present in games_clean$mechanic
for(j in 1:length(cat_terms)){
  for(i in 1:length(games_clean$category)){
    games_clean[i, as.character(cat_terms[j])] <- as.numeric(grepl(cat_terms[j], games_clean$category[i]))
  }
  cat("now at", round(j * 1.19), "% ... ")
}

# head(games_clean)
```
### Rename Categories
```{r}
colnames(games_clean) <- tolower(colnames(games_clean))
colnames(games_clean) <- gsub("co-op", "coop", colnames(games_clean)) # odd one out with dash
colnames(games_clean) <- gsub("\\/", " ", colnames(games_clean))
colnames(games_clean) <- gsub("&", "", colnames(games_clean))
colnames(games_clean) <- gsub("-", " ", colnames(games_clean))
colnames(games_clean) <- gsub(" and ", " ", colnames(games_clean))
colnames(games_clean) <- gsub("  ", " ", colnames(games_clean))
colnames(games_clean) <- gsub("  ", " ", colnames(games_clean))
colnames(games_clean) <- gsub(" ", "_", colnames(games_clean))
colnames(games_clean) <- gsub("\\'", "", colnames(games_clean))

cat_old_names <- colnames(select(games_clean, abstract_strategy:zombies))
cat_new_names <- paste0('cat_', cat_old_names)
setnames(games_clean, old = cat_old_names, new = cat_new_names)
head(games_clean)
head(select(games_clean, cat_abstract_strategy:cat_zombies))
```
### Total Categories
```{r}
games_clean <- games_clean %>%
  mutate(cat_total = rowSums(select(games_clean, cat_abstract_strategy:cat_zombies)))
summary(games_clean$cat_total)
```
### Save games_clean
```{r}
write_csv(games_clean, "games_clean.csv")
```

### Check Nones
```{r}
sum(games_clean$cat_none)
cat_miss <- games_clean[games_clean$cat_none == 1, ]
```
### Check Both Missing
```{r}
missing_all <- cat_miss[cat_miss$mech_none == 1, ]
```

### Review Category Stats
```{r}
describe(select(games_clean, cat_abstract_strategy:cat_zombies))
```


### Check Some Stats!
```{r}
filter(games_clean, grepl("harbour", ignore.case = TRUE, names))
filter(games_clean, grepl("pandemic", ignore.case = TRUE, names))
filter(games_clean, grepl("cthulhu", ignore.case = TRUE, names))
filter(games_clean, grepl("tiny epic", ignore.case = TRUE, names))
filter(games_clean, grepl("catan", ignore.case = TRUE, names))
game_expansions <- games_clean %>%
  filter(cat_expansion_for_base_game == 1)
game_expansions
```

### Times
```{r}
describe(games_clean$avg_time)
```

### Num Players


## Quick LM
```{r error=TRUE}
lm_sub <- games_clean %>%
  select(min_players:cat_total, -num_votes, -image_url, -mechanic, -category, -designer, -owned, -avg_rating, -mech_total, -cat_total)
lm1 <- lm(geek_rating ~ ., data = lm_sub)
summary(lm1)
```


## Plotting
```{r}
gg <- ggplot(data = games_clean, aes(x = geek_rating, y = owned, col = avg_time))
gg <- gg + geom_point(alpha = 0.6)
gg <- gg + geom_smooth()
gg

```
## Quick Load of Cleaned Data
```{r}
games_clean <- read_csv("~/bgg_explorer/games_clean.csv") # added to start here without rerunning everything
```

## PCA Analysis
```{r}
numeric <- map_lgl(games_clean, is.numeric)
games_numeric <- games_clean[, numeric]
pr_games <- prcomp(games_numeric, scale = TRUE)
```


#So we don't explain a lot of the variance very quickly
```{r}
pr_var <- pr_games$sdev ^ 2
pve <- pr_var / sum(pr_var)

cumsum(pve)
```

```{r error=TRUE}
PCA_games <- PCAproj(games_numeric, scale = sd)

par(mar = c(5,4,3,3) + .1, las = 1, cex = 0.2)
biplot(PCA_games, scale = 0, ylim = c(-5, 9))
```
#K means clustering (do we want consistency or no?)
```{r}
set.seed(12345)
games_numeric_2 <- select(games_numeric, -c("game_id", "rank", "avg_rating", "num_votes", "min_time", "max_time"))
km_games <- kmeans(games_numeric_2, centers = 500, nstart = 25)
with(games_numeric_2, plot(geek_rating, owned, col = km_games$cluster, pch = 20, main = "Stuff"))
```
## Lookup function
```{r}
lookup <- function(gamenamepart){
  games_clean$names[str_detect(games_clean$names, fixed(gamenamepart, ignore_case = T))]
}
lookup("tiny epic")
```

## basic recommendations
```{r}
recommendation <- function(gamename = "Gloomhaven"){
  detect <- str_detect(games_clean$names, paste0("^", gamename, "$"))
  detected <- which(detect)[1]
  cluster <- km_games$cluster[detected]
  head(games_clean$names[which(km_const$cluster == cluster)])
}
```

#Score from 1 to 5
```{r}
recommendation2 <- function(gamename = "Gloomhaven"){
Score <- as.data.frame(cbind(games_clean$names, "score" = 0))
Score$score <- as.numeric(Score$score) - 1
detect <- str_detect(games_clean$names, paste0("^", gamename, "$"))
detected <- which(detect)[1]
Score[detected, ] <- NA # stops it from recommending itself
set.seed(12345)
  for (i in 1:5){
      km_games <- kmeans(games_numeric_2, centers = 500, nstart = 25)
      cluster <- km_games$cluster[detected]
      Score$score[which(km_games$cluster == cluster)] <- Score$score[which(km_games$cluster == cluster)] + 1
    }
  head(arrange(Score, desc(score)), n = 10)
}
```
#Doesn't repeat
```{r}
recommendation2("Betrayal")
```

```{r}
Score <- as.data.frame(cbind(games_clean$names, "score" = 0))
Score$score <- as.numeric(Score$score) - 1
detect <- str_detect(games_clean$names, "Pandemic")
detected <- which(detect)[1]
Score <- Score[-detected,]
    for (i in 1:5){
      km_games <- kmeans(games_numeric_2, centers = 500, nstart = 25)
      cluster <- km_games$cluster[detected]
      Score$score[which(km_games$cluster == cluster)] <- Score$score[which(km_games$cluster == cluster)] + 1
    }
  head(arrange(Score, desc(score)), n = 20)
```


## Supervised Learning

### Subset
Drop unimportant variables
```{r}
games_clean_sub <- games_clean %>%
  select(min_players:cat_total, -num_votes, -image_url, -mechanic, -category, -designer, -owned, -avg_rating, -mech_total, -cat_total)
lm1 <- lm(geek_rating ~ ., data = games_clean_sub)
summary(lm1)
```

### Training
```{r}
library(caret)

in_train <- createDataPartition(y = games_clean_sub$geek_rating,
                                p = 3 / 4, list = FALSE)
str(in_train)
games_clean_training <- games_clean_sub[ in_train, ]
games_clean_testing  <- games_clean_sub[-in_train, ]
```

### OLS

Step 1: Solve an optimization problem using the pre-processed training data
```{r}
fit <- train(geek_rating ~ ., data = games_clean_training, method = "lm", 
             preProcess = c("center", "scale"))
fit
```

Step 2: Predict in the testing data
```{r}
y_hat_lm <- predict(fit, newdata = games_clean_testing)
```

Step 3: Evaluate
```{r}
defaultSummary(data.frame(obs = games_clean_testing$geek_rating, pred = y_hat))
```

So our testing data using the OLS model actually had as lightly better RMSE score than in the training data.


### Lasso
Initialize Grid
```{r}
set.seed(12345)
lassoGrid <- expand.grid(.lambda = seq(.05, 1, length = 10),
                        .fraction = seq(.05, 1, length = 10))
# head(lassoGrid, n = 20)
```

```{r cache=TRUE}
set.seed(12345)
lasso <- train(geek_rating ~ ., data = games_clean_training, method = "enet", 
               trControl = ctrl, tuneGrid = lassoGrid)
```

Prediction
```{r}
y_hat_lasso <- predict(lasso, newdata = games_clean_testing)
# mean( (games_clean_testing$geek_rating - y_hat) ^ 2 )
defaultSummary(data.frame(obs = games_clean_testing$geek_rating, pred = y_hat_lasso))
```
Lasso penalized prediction is just MARGINALLY better than the OLS model.

### Random Forest
Detect Parallel Cores
```{r}
library(doMC)
registerDoMC(parallel::detectCores())
```

```{r cache=TRUE}
# library(randomForest)
rf_grid <- data.frame(.mtry = 2:(ncol(games_clean_training) - 1L))
rf_out <- train(geek_rating ~ ., data = games_clean_training, method = "rf",
             trControl = ctrl, tuneGrid = rf_grid, 
             ntrees = 1000, importance = TRUE)
varImp(rf_out)
y_hat_rf <- predict(out, newdata = games_clean_testing)
defaultSummary(data.frame(obs = games_clean_testing$geek_rating, 
                          pred = exp(y_hat_rf)))
```

### BART
```{r}
library(BART)
X_train <- model.matrix(geek_rating ~ ., data = games_clean_training)
X_test <- model.matrix(geek_rating ~ ., data = games_clean_testing)
out <- mc.wbart(X_train, y = games_clean_training$geek_rating, X_test,
                mc.cores = parallel::detectCores())
defaultSummary(data.frame(obs = games_clean_testing$geek_rating,
                          pred = exp(out$yhat.test.mean)))
```


